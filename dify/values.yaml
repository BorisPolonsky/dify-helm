# Default values for dify.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  api:
    repository: langgenius/dify-api
    tag: 0.3.1
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName
  web:    
    repository: langgenius/dify-web
    tag: 0.3.1
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName
  proxy:
    repository: nginx
    tag: latest
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName

api:
  enabled: true
  replicas: 1
  resources: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  extraEnv: {}
  # Apply your own Environment Variables if necessary
  # - name: LANG
  #   value: "C.UTF-8"
  service:
    port: 5001
    annotations: {}
    labels: {}
    clusterIP: ""
  url:
    # The base URL of console application, refers to the Console base URL of WEB service if console domain is
    # different from api or web app domain.
    # example: http://cloud.dify.ai
    console: ''
    # The URL for Service API endpoints，refers to the base URL of the current API service if api domain is
    # different from console domain.
    # example: http://api.dify.ai
    api: ''
    # The URL for Web APP, refers to the Web App base URL of WEB service if web app domain is different from
    # console or api domain.
    # example: http://udify.app
    app: ''
  # When enabled, migrations will be executed prior to application startup and the application will start after the migrations have completed.
  migration: true
  # A secret key that is used for securely signing the session cookie and encrypting sensitive information on the database. You can generate a strong key using `openssl rand -base64 42`.
  secretKey: 'sk-9f73s3ljTXVcMT3Blb3ljTqtsKiGHXVcMT3BlbkFJLK7U'

worker:
  enabled: true
  replicas: 1
  resources: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  extraEnv: {}
  # Apply your own Environment Variables if necessary
  # - name: LANG
  #   value: "C.UTF-8"

proxy:
  enabled: true
  replicas: 1
  resources: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  extraEnv: {}
  # Apply your own Environment Variables if necessary
  # - name: LANG
  #   value: "C.UTF-8"
  persistence:
    mountPath: "/var/log/nginx"
    ## If true, create/use a Persistent Volume Claim for log
    ## If false, flush logs to stdout & stderr
    ##
    enabled: false
    annotations:
      helm.sh/resource-policy: keep
    persistentVolumeClaim:
      existingClaim: ""
      ## Nginx Logs Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.
      ## ReadWriteMany access mode required for nginx
      ##
      storageClass:
      accessModes: ReadWriteMany
      size: 1Gi
      subPath: ""
  service:
    port: 80
    annotations: {}
    labels: {}
    clusterIP: ""

web:
  enabled: true
  replicas: 1
  resources: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  extraEnv: {}
  # Apply your own Environment Variables if necessary
  # - name: LANG
  #   value: "C.UTF-8"
  service:
    port: 3000
    annotations: {}
    labels: {}
    clusterIP: ""

postgres:
  enabled: true
  name: postgresql
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: 15.3.0-debian-11-r7
    digest: ""
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    ## Set to true if you would like to see extra information on logs
    ##
    debug: false
  ## Authentication parameters
  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#setting-the-root-password-on-first-run
  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#creating-a-database-on-first-run
  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql#creating-a-database-user-on-first-run
  ##
  auth:
    ## @param auth.enablePostgresUser Assign a password to the "postgres" admin user. Otherwise, remote access will be blocked for this user
    ##
    enablePostgresUser: true
    ## @param auth.postgresPassword Password for the "postgres" admin user. Ignored if `auth.existingSecret` is provided
    ##
    postgresPassword: "difyai123456"
    ## @param auth.username Name for a custom user to create
    ##
    # TODO: align ENV & svc
    username: "postgres"
    ## @param auth.password Password for the custom user to create. Ignored if `auth.existingSecret` is provided
    ##
    password: ""
    ## @param auth.database Name for a custom database to create
    ##
    database: "dify"
    ## @param auth.replicationUsername Name of the replication user
    ##
    replicationUsername: repl_user
    ## @param auth.replicationPassword Password for the replication user. Ignored if `auth.existingSecret` is provided
    ##
    replicationPassword: ""
    ## @param auth.existingSecret Name of existing secret to use for PostgreSQL credentials. `auth.postgresPassword`, `auth.password`, and `auth.replicationPassword` will be ignored and picked up from this secret. The secret might also contains the key `ldap-password` if LDAP is enabled. `ldap.bind_password` will be ignored and picked from this secret in this case.
    ##
    existingSecret: ""
    ## @param auth.secretKeys.adminPasswordKey Name of key in existing secret to use for PostgreSQL credentials. Only used when `auth.existingSecret` is set.
    ## @param auth.secretKeys.userPasswordKey Name of key in existing secret to use for PostgreSQL credentials. Only used when `auth.existingSecret` is set.
    ## @param auth.secretKeys.replicationPasswordKey Name of key in existing secret to use for PostgreSQL credentials. Only used when `auth.existingSecret` is set.
    ##
    secretKeys:
      adminPasswordKey: postgres-password
      userPasswordKey: password
      replicationPasswordKey: replication-password
    ## @param auth.usePasswordFiles Mount credentials as a files instead of using an environment variable
    ##
    usePasswordFiles: false
  ## @param architecture PostgreSQL architecture (`standalone` or `replication`)
  ##
  architecture: standalone
  ## Replication configuration
  ## Ignored if `architecture` is `standalone`
  ##
  replication:
    ## @param replication.synchronousCommit Set synchronous commit mode. Allowed values: `on`, `remote_apply`, `remote_write`, `local` and `off`
    ## @param replication.numSynchronousReplicas Number of replicas that will have synchronous replication. Note: Cannot be greater than `readReplicas.replicaCount`.
    ## ref: https://www.postgresql.org/docs/current/runtime-config-wal.html#GUC-SYNCHRONOUS-COMMIT
    ##
    synchronousCommit: "off"
    numSynchronousReplicas: 0
    ## @param replication.applicationName Cluster application name. Useful for advanced replication settings
    ##
    applicationName: my_application


weaviate:
  enabled: false
  image:
    # registry where weaviate image is stored
    registry: docker.io
    # Tag of weaviate image to deploy
    # Note: We strongly recommend you overwrite this value in your own values.yaml.
    # Otherwise a mere upgrade of the chart could lead to an unexpected upgrade
    # of weaviate. In accordance with Infra-as-code, you should pin this value
    # down and only change it if you explicitly want to upgrade the Weaviate
    # version.
    tag: 1.19.1
    repo: semitechnologies/weaviate
    # Image pull policy: https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy
    pullPolicy: IfNotPresent
    pullSecrets: []

  # overwrite command and args if you want to run specific startup scripts, for
  # example setting the nofile limit
  command: ["/bin/weaviate"]
  args:
    - '--host'
    - '0.0.0.0'
    - '--port'
    - '8080'
    - '--scheme'
    - 'http'
    - '--config-file'
    - '/weaviate-config/conf.yaml'
    - --read-timeout=60s 
    - --write-timeout=60s

  # below is an example that can be used to set an arbitrary nofile limit at
  # startup:
  #
  # command: 
  #   - "/bin/sh"
  # args: 
  #   - "-c"
  #   - "ulimit -n 65535 && /bin/weaviate --host 0.0.0.0 --port 8080 --scheme http --config-file /weaviate-config/conf.yaml"


  # it is possible to change the sysctl's 'vm.max_map_count' using initContainer for Weaviate,
  # the init Container runs before Weaviate Container and sets the value for the WHOLE node
  # to the one provided below.
  # it is possible to run additional initContainer before Weaviate is up and running. You can specify the
  # containers as a list in `extraInitContainers`, exactly how they are defined in a kubernetes manifest:
  #   https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  initContainers:
    sysctlInitContainer:
      enabled: true
      sysctlVmMaxMapCount: 524288
      image:
        registry: docker.io
        repo: alpine
        tag: latest
        pullPolicy: IfNotPresent
    
    extraInitContainers: {}
    # - image: some-image
    #   name: some-name

  # Scale replicas of Weaviate. Note that as of v1.8.0 dynamic scaling is limited
  # to cases where no data is imported yet. Scaling down after importing data may
  # break usability. Full dynamic scalability will be added in a future release.
  replicas: 1
  resources: {}
    # requests:
    #   cpu: '500m'
    #   memory: '300Mi'
    # limits:
    #   cpu: '1000m'
    #   memory: '1Gi'


  # Add a service account ot the Weaviate pods if you need Weaviate to have permissions to
  # access kubernetes resources or cloud provider resources. For example for it to have
  # access to a backup up bucket, or if you want to restrict Weaviate pod in any way.
  # By default, use the default ServiceAccount
  serviceAccountName:

  # The Persistent Volume Claim settings for Weaviate. If there's a
  # storage.fullnameOverride field set, then the default pvc will not be
  # created, instead the one defined in fullnameOverride will be used
  storage:
    size: 32Gi
    storageClassName: ""

  # The service controls how weaviate is exposed to the outside world. If you
  # don't want a public load balancer, you can also choose 'ClusterIP' to make
  # weaviate only accessible within your cluster.
  service:
    name: weaviate
    ports:
      - name: http
        protocol: TCP
        port: 80
        # Target port is going to be the same for every port
    type: LoadBalancer
    loadBalancerSourceRanges: []
    # optionally set cluster IP if you want to set a static IP
    clusterIP:
    annotations: {}

  # Adjust liveness, readiness and startup probes configuration
  startupProbe:
    # For kubernetes versions prior to 1.18 startupProbe is not supported thus can be disabled.
    enabled: false

    initialDelaySeconds: 300
    periodSeconds: 60
    failureThreshold: 50
    successThreshold: 1
    timeoutSeconds: 3

  livenessProbe:
    initialDelaySeconds: 900
    periodSeconds: 10
    failureThreshold: 30
    successThreshold: 1
    timeoutSeconds: 3

  readinessProbe:
    initialDelaySeconds: 3
    periodSeconds: 10
    failureThreshold: 3
    successThreshold: 1
    timeoutSeconds: 3


  terminationGracePeriodSeconds: 600

  # Weaviate Config
  #
  # The following settings allow you to customize Weaviate to your needs, for
  # example set authentication and authorization options. See weaviate docs
  # (https://www.weaviate.io/developers/weaviate/) for all
  # configuration.
  authentication:
    anonymous_access:
      enabled: true
    # This configuration allows to add API keys to Weaviate. This configuration allows only
    # plain text API Keys, if you want to store the API Keys in a Kubernetes secret you can
    # configure the same configuration with ENV Vars. Read the `env` section below on what
    # needs to be configured. If using ENV Vars over this make sure to comment out the whole
    # `apikey` section (as it is by default). ENV Vars has priority over this config.
    # apikey:
    #   enabled: false
    #   # Any number of allowed API Keys as plain text
    #   allowed_keys:
    #     - readOnly-plainText-API-Key
    #     - admin-plainText-API-Key
    #   # You can either set a single user for all the listed Allowed API keys OR
    #   # one user per API Key, i.e. length(apikey.allowed_keys) == length(apikey.users) OR
    #   # length(apikey.users) == 1
    #   # NOTE: Make sure the lister Users are added to the Authorization as well.
    #   users:
    #     - api-key-user-readOnly
    #     - api-key-user-admin
    oidc:
      enabled: false
      # issuer: ''
      # username_claim: ''
      # groups_claim: ''
      # client_id: ''

  authorization:
    admin_list:
      enabled: false
      # users:
      # - admin_user1
      # - admin_user2
      # - api-key-user-admin
      # read_only_users:
      # - readonly_user1
      # - readonly_user2
      # - api-key-user-readOnly

  query_defaults:
    limit: 100
  debug: false


  # Insert any custom environment variables or envSecrets by putting the exact name
  # and desired value into the settings below. Any env name passed will be automatically
  # set for the statefulSet.
  env:
    CLUSTER_GOSSIP_BIND_PORT: 7000
    CLUSTER_DATA_BIND_PORT: 7001
    # The aggressiveness of the Go Garbage Collector. 100 is the default value.
    GOGC: 100

    # Expose metrics on port 2112 for Prometheus to scrape
    PROMETHEUS_MONITORING_ENABLED: false

    # Set a MEM limit for the Weaviate Pod so it can help you both increase GC-related 
    # performance as well as avoid GC-related out-of-memory (“OOM”) situations
    # GOMEMLIMIT: 6GiB

    # Maximum results Weaviate can query with/without pagination
    # NOTE: Affects performance, do NOT set to a very high value.
    # The default is 100K
    QUERY_MAXIMUM_RESULTS: 100000

    # whether to enable vector dimensions tracking metric
    TRACK_VECTOR_DIMENSIONS: false

    # whether to re-index/-compute the vector dimensions metric (needed if upgrading from weaviate < v1.16.0)
    REINDEX_VECTOR_DIMENSIONS_AT_STARTUP: false

    ##########################
    # API Keys with ENV Vars #
    ##########################
    # If using ENV Vars to set up API Keys make sure to have `authentication.apikey` block commented out
    # to avoid any future changes. ENV Vars has priority over the config above `authentication.apikey`.
    # If using `authentication.apikey `the below ENV Vars will be used because they have priority,
    # so comment them out to avoid any future changes.
    # Enables API key authentication. If it is set to 'false' the AUTHENTICATION_APIKEY_ALLOWED_KEYS
    # and AUTHENTICATION_APIKEY_USERS will not have any effect.
    # AUTHENTICATION_APIKEY_ENABLED: 'true'

    # List one or more keys, separated by commas. Each key corresponds to a specific user identity below.
    # If you want to use a kubernetes secret for the API Keys comment out this Variable and use the one in `envSecrets` below
    # AUTHENTICATION_APIKEY_ALLOWED_KEYS: 'jane-secret-key,ian-secret-key'  (plain text)

    # List one or more user identities, separated by commas. You can have only one User for all the keys or one user per key.
    # The User/s can be a simple name or an email, no matter if it exists or not.
    # NOTE: Make sure to add the users to the authorization above overwise they will not be allowed to interact with Weaviate.
    # AUTHENTICATION_APIKEY_USERS: 'jane@doe.com,ian-smith'

  envSecrets:
    # create a Kubernetes secret with AUTHENTICATION_APIKEY_ALLOWED_KEYS key and its respective value
    # AUTHENTICATION_APIKEY_ALLOWED_KEYS: name-of-the-k8s-secret-containing-the-comma-separated-api-keys

  # Configure backup providers
  backups:
    # The backup-filesystem module enables creation of the DB backups in
    # the local filesystem
    filesystem:
      enabled: false
      envconfig:
        # Configure folder where backups should be saved
        BACKUP_FILESYSTEM_PATH: /tmp/backups
    
    s3:
      enabled: false
      # If one is using AWS EKS and has already configured K8s Service Account
      # that holds the AWS credentials one can pass a name of that service account
      # here using this setting.
      # NOTE: the root `serviceAccountName` config has priority over this one, and 
      # if the root one is set this one will NOT overwrite it. This one is here for
      # backwards compatibility.
      serviceAccountName:

      envconfig:
        # Configure bucket where backups should be saved, this setting is mandatory
        BACKUP_S3_BUCKET: weaviate-backups

        # Optional setting. Defaults to empty string. 
        # Set this option if you want to save backups to a given location
        # inside the bucket
        # BACKUP_S3_PATH: path/inside/bucket

        # Optional setting. Defaults to AWS S3 (s3.amazonaws.com). 
        # Set this option if you have a MinIO storage configured in your environment
        # and want to use it instead of the AWS S3.
        # BACKUP_S3_ENDPOINT: custom.minio.endpoint.address

        # Optional setting. Defaults to true. 
        # Set this option if you don't want to use SSL.
        # BACKUP_S3_USE_SSL: true

        # You can pass environment AWS settings here:
        # Define the region
        # AWS_REGION: eu-west-1

      # For Weaviate to be able to create bucket objects it needs a user credentials to authenticate to AWS.
      # The User must have permissions to read/create/delete bucket objects.
      # You can pass the User credentials (access-key id and access-secret-key) in 2 ways:
      # 1. by setting the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY plain values in the `secrets` section below
      #     this chart will create a kubernetes secret for you with these key-values pairs
      # 2. create Kubernetes secret/s with AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY  keys and their respective values 
      #     Set the Key and the secret where it is set in `envSecrets` section below
      secrets: {}
      #   AWS_ACCESS_KEY_ID: access-key-id (plain text)
      #   AWS_SECRET_ACCESS_KEY: secret-access-key (plain text)

      # If one has already defined secrets with AWS credentials one can pass them using
      # this setting:
      envSecrets: {}
      #   AWS_ACCESS_KEY_ID: name-of-the-k8s-secret-containing-the-key-id
      #   AWS_SECRET_ACCESS_KEY: name-of-the-k8s-secret-containing-the-key

    gcs:
      enabled: false
      envconfig:
        # Configure bucket where backups should be saved, this setting is mandatory
        BACKUP_GCS_BUCKET: weaviate-backups

        # Optional setting. Defaults to empty string.
        # Set this option if you want to save backups to a given location
        # inside the bucket
        # BACKUP_GCS_PATH: path/inside/bucket

        # You can pass environment Google settings here:
        # Define the project
        # GOOGLE_CLOUD_PROJECT: project-id

      # For Weaviate to be able to create bucket objects it needs a ServiceAccount credentials to authenticate to GCP.
      # The ServiceAccount must have permissions to read/create/delete bucket objects.
      # You can pass the ServiceAccount credentials (as JSON) in 2 ways:
      # 1. by setting the GOOGLE_APPLICATION_CREDENTIALS json as plain text in the `secrets` section below
      #     this chart will create a kubernetes secret for you with this key-values pairs
      # 2. create a Kubernetes secret with GOOGLE_APPLICATION_CREDENTIALS key and its respective value
      #     Set the Key and the secret where it is set in `envSecrets` section below
      secrets: {}
      #   GOOGLE_APPLICATION_CREDENTIALS: credentials-json-string (plain text)

      # If one has already defined a secret with GOOGLE_APPLICATION_CREDENTIALS one can pass them using
      # this setting:
      envSecrets: {}
      #   GOOGLE_APPLICATION_CREDENTIALS: name-of-the-k8s-secret-containing-the-key

    azure:
      enabled: false
      envconfig:
        # Configure container where backups should be saved, this setting is mandatory
        BACKUP_AZURE_CONTAINER: weaviate-backups

        # Optional setting. Defaults to empty string. 
        # Set this option if you want to save backups to a given location
        # inside the container
        # BACKUP_AZURE_PATH: path/inside/container

      # For Weaviate to be able to create container objects it needs a user credentials to authenticate to Azure Storage.
      # The User must have permissions to read/create/delete container objects.
      # You can pass the User credentials (account-name id and account-key or connection-string) in 2 ways:
      # 1. by setting the AZURE_STORAGE_ACCOUNT and AZURE_STORAGE_KEY
      #     or AZURE_STORAGE_CONNECTION_STRING plain values in the `secrets` section below
      #     this chart will create a kubernetes secret for you with these key-values pairs
      # 2. create Kubernetes secret/s with AZURE_STORAGE_ACCOUNT and AZURE_STORAGE_KEY 
      #     or AZURE_STORAGE_CONNECTION_STRING and their respective values
      #     Set the Key and the secret where it is set in `envSecrets` section below
      secrets: {}
      #   AZURE_STORAGE_ACCOUNT: account-name (plain text)
      #   AZURE_STORAGE_KEY: account-key (plain text)
      #   AZURE_STORAGE_CONNECTION_STRING: connection-string (plain text)

      # If one has already defined secrets with Azure Storage credentials one can pass them using
      # this setting:
      envSecrets: {}
      #   AZURE_STORAGE_ACCOUNT: name-of-the-k8s-secret-containing-the-account-name
      #   AZURE_STORAGE_KEY: name-of-the-k8s-secret-containing-account-key
      #   AZURE_STORAGE_CONNECTION_STRING: name-of-the-k8s-secret-containing-connection-string


  # modules are extensions to Weaviate, they can be used to support various
  # ML-models, but also other features unrelated to model inference.
  # An inference/vectorizer module is not required, you can also run without any
  # modules and import your own vectors.
  modules:

    # The text2vec-contextionary module uses a fastText-based vector-space to
    # derive vector embeddings for your objects. It is very efficient on CPUs,
    # but in some situations it cannot reach the same level of accuracy as
    # transformers-based models.
    text2vec-contextionary:
      # disable if you want to use transformers or import or own vectors
      enabled: false

      # The configuration below is ignored if enabled==false
      fullnameOverride: contextionary
      tag: en0.16.0-v1.0.2
      repo: semitechnologies/contextionary
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      envconfig:
        occurrence_weight_linear_factor: 0.75
        neighbor_occurrence_ignore_percentile: 5
        enable_compound_splitting: false
        extensions_storage_mode: weaviate
      resources:
        requests:
          cpu: '500m'
          memory: '500Mi'
        limits:
          cpu: '1000m'
          memory: '5000Mi'

      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

    # The text2vec-transformers modules uses neural networks, such as BERT,
    # DistilBERT, etc. to dynamically compute vector embeddings based on the
    # sentence's context. It is very slow on CPUs and should run with
    # CUDA-enabled GPUs for optimal performance.
    text2vec-transformers:

      # enable if you want to use transformers instead of the
      # text2vec-contextionary module
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}
      # The configuration below is ignored if enabled==false

      # replace with model of choice, see
      # https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers
      # for all supported models or build your own container.
      tag: distilbert-base-uncased
      repo: semitechnologies/transformers-inference
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: transformers-inference
      # Deprecated setting use initialDelaySeconds instead in each probe instead
      # probeInitialDelaySeconds: 120
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
      envconfig:
        # enable for CUDA support. Your K8s cluster needs to be configured
        # accordingly and you need to explicitly set GPU requests & limits below
        enable_cuda: false

        # only used when cuda is enabled
        nvidia_visible_devices: all
        nvidia_driver_capabilities: compute,utility

        # only used when cuda is enabled
        ld_library_path: /usr/local/nvidia/lib64

      resources:
        requests:
          cpu: '1000m'
          memory: '3000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
        limits:
          cpu: '1000m'
          memory: '5000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
      
      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

      passageQueryServices:
        passage:
          enabled: false
          # You can set directly an inference URL of this module without deploying it with this release.
          # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
          inferenceUrl: {}

          tag: facebook-dpr-ctx_encoder-single-nq-base
          repo: semitechnologies/transformers-inference
          registry: docker.io
          imagePullSecrets: []
          replicas: 1
          fullnameOverride: transformers-inference-passage
          livenessProbe:
            initialDelaySeconds: 120
            periodSeconds: 3
            timeoutSeconds: 3
          readinessProbe:
            initialDelaySeconds: 120
            periodSeconds: 3
          envconfig:
            # enable for CUDA support. Your K8s cluster needs to be configured
            # accordingly and you need to explicitly set GPU requests & limits below
            enable_cuda: false

            # only used when cuda is enabled
            nvidia_visible_devices: all
            nvidia_driver_capabilities: compute,utility

            # only used when cuda is enabled
            ld_library_path: /usr/local/nvidia/lib64

          resources:
            requests:
              cpu: '1000m'
              memory: '3000Mi'

              # enable if running with CUDA support
              # nvidia.com/gpu: 1
            limits:
              cpu: '1000m'
              memory: '5000Mi'

              # enable if running with CUDA support
              # nvidia.com/gpu: 1
          
          # You can guide where the pods are scheduled on a per-module basis,
          # as well as for Weaviate overall. Each module accepts nodeSelector,
          # tolerations, and affinity configuration. If it is set on a per-
          # module basis, this configuration overrides the global config.

          nodeSelector:
          tolerations:
          affinity:

        query:
          enabled: false
          # You can set directly an inference URL of this module without deploying it with this release.
          # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
          inferenceUrl: {}

          tag: facebook-dpr-question_encoder-single-nq-base
          repo: semitechnologies/transformers-inference
          registry: docker.io
          imagePullSecrets: []
          replicas: 1
          fullnameOverride: transformers-inference-query
          livenessProbe:
            initialDelaySeconds: 120
            periodSeconds: 3
            timeoutSeconds: 3
          readinessProbe:
            initialDelaySeconds: 120
            periodSeconds: 3
          envconfig:
            # enable for CUDA support. Your K8s cluster needs to be configured
            # accordingly and you need to explicitly set GPU requests & limits below
            enable_cuda: false

            # only used when cuda is enabled
            nvidia_visible_devices: all
            nvidia_driver_capabilities: compute,utility

            # only used when cuda is enabled
            ld_library_path: /usr/local/nvidia/lib64

          resources:
            requests:
              cpu: '1000m'
              memory: '3000Mi'

              # enable if running with CUDA support
              # nvidia.com/gpu: 1
            limits:
              cpu: '1000m'
              memory: '5000Mi'

              # enable if running with CUDA support
              # nvidia.com/gpu: 1
          
          # You can guide where the pods are scheduled on a per-module basis,
          # as well as for Weaviate overall. Each module accepts nodeSelector,
          # tolerations, and affinity configuration. If it is set on a per-
          # module basis, this configuration overrides the global config.

          nodeSelector:
          tolerations:
          affinity:

    # The text2vec-openai module uses OpenAI Embeddings API
    # to dynamically compute vector embeddings based on the
    # sentence's context.
    # More information about OpenAI Embeddings API can be found here:
    # https://beta.openai.com/docs/guides/embeddings/what-are-embeddings
    text2vec-openai:

      # enable if you want to use OpenAI module
      enabled: false

      # Set your OpenAI API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The text2vec-huggingface module uses HuggingFace API
    # to dynamically compute vector embeddings based on the
    # sentence's context.
    # More information about HuggingFace API can be found here:
    # https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task
    text2vec-huggingface:

      # enable if you want to use HuggingFace module
      enabled: false

      # Set your HuggingFace API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The text2vec-cohere module uses Cohere API
    # to dynamically compute vector embeddings based on the
    # sentence's context.
    # More information about Cohere API can be found here: https://docs.cohere.ai/
    text2vec-cohere:

      # enable if you want to use Cohere module
      enabled: false

      # Set your Cohere API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The text2vec-palm module uses Google PaLM Embeddings API
    # to dynamically compute vector embeddings based on the
    # sentence's context.
    # More information about Google PaLM Embeddings API can be found here:
    # https://developers.generativeai.google/
    text2vec-palm:

      # enable if you want to use Google PaLM module
      enabled: false

      # Set your Google PaLM API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The ref2vec-centroid module
    ref2vec-centroid:

      # enable if you want to use Centroid module
      enabled: false

    # The multi2vec-clip modules uses CLIP transformers to vectorize both images
    # and text in the same vector space. It is typically slow(er) on CPUs and should
    # run with CUDA-enabled GPUs for optimal performance.
    multi2vec-clip:

      # enable if you want to use transformers instead of the
      # text2vec-contextionary module
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}

      # The configuration below is ignored if enabled==false

      # replace with model of choice, see
      # https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-clip
      # for all supported models or build your own container.
      tag: sentence-transformers-clip-ViT-B-32-multilingual-v1
      repo: semitechnologies/multi2vec-clip
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: clip-inference
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
      envconfig:
        # enable for CUDA support. Your K8s cluster needs to be configured
        # accordingly and you need to explicitly set GPU requests & limits below
        enable_cuda: false

        # only used when cuda is enabled
        nvidia_visible_devices: all
        nvidia_driver_capabilities: compute,utility

        # only used when cuda is enabled
        ld_library_path: /usr/local/nvidia/lib64

      resources:
        requests:
          cpu: '1000m'
          memory: '3000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
        limits:
          cpu: '1000m'
          memory: '5000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
      annotations:
      nodeSelector:
      tolerations:

    # The qna-transformers module uses neural networks, such as BERT,
    # DistilBERT, to find an aswer in text to a given question
    qna-transformers:
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}
      tag: bert-large-uncased-whole-word-masking-finetuned-squad-34d66b1
      repo: semitechnologies/qna-transformers
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: qna-transformers
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
      envconfig:
        # enable for CUDA support. Your K8s cluster needs to be configured
        # accordingly and you need to explicitly set GPU requests & limits below
        enable_cuda: false

        # only used when cuda is enabled
        nvidia_visible_devices: all
        nvidia_driver_capabilities: compute,utility

        # only used when cuda is enabled
        ld_library_path: /usr/local/nvidia/lib64

      resources:
        requests:
          cpu: '1000m'
          memory: '3000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
        limits:
          cpu: '1000m'
          memory: '5000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
      
      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

    # The qna-openai module uses OpenAI Completions API
    # to dynamically answer given questions.
    # More information about OpenAI Completions API can be found here:
    # https://beta.openai.com/docs/api-reference/completions
    qna-openai:

      # enable if you want to use OpenAI module
      enabled: false

      # Set your OpenAI API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The generative-openai module uses OpenAI Completions API
    # along with text-davinci-003 model to behave as ChatGPT.
    # More information about OpenAI Completions API can be found here:
    # https://beta.openai.com/docs/api-reference/completions
    generative-openai:

      # enable if you want to use OpenAI module
      enabled: false

      # Set your OpenAI API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The generative-cohere module uses Cohere Generate API
    # More information about Cohere's Generate API can be found here:
    # https://docs.cohere.com/reference/generate
    generative-cohere:

      # enable if you want to use Cohere generative module
      enabled: false

      # Set your Cohere API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The generative-palm module uses Google PaLM API.
    # More information about Google PaLM API can be found here:
    # https://developers.generativeai.google/
    generative-palm:

      # enable if you want to use Google PaLM module
      enabled: false

      # Set your Google PaLM API Key to be passed to Weaviate pod as
      # an environment variable
      apiKey: ''

    # The img2vec-neural module uses neural networks, to generate
    # a vector representation of the image
    img2vec-neural:
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}
      tag: resnet50
      repo: semitechnologies/img2vec-pytorch
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: img2vec-neural
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
      envconfig:
        # enable for CUDA support. Your K8s cluster needs to be configured
        # accordingly and you need to explicitly set GPU requests & limits below
        enable_cuda: false

        # only used when cuda is enabled
        nvidia_visible_devices: all
        nvidia_driver_capabilities: compute,utility

        # only used when cuda is enabled
        ld_library_path: /usr/local/nvidia/lib64

      resources:
        requests:
          cpu: '1000m'
          memory: '3000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
        limits:
          cpu: '1000m'
          memory: '5000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
      
      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

    # The text-spellcheck module uses spellchecker library to check
    # misspellings in a given text
    text-spellcheck:
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}
      tag: pyspellchecker-en
      repo: semitechnologies/text-spellcheck-model
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: text-spellcheck
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3

      resources:
        requests:
          cpu: '400m'
          memory: '400Mi'
        limits:
          cpu: '500m'
          memory: '500Mi'
      
      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

    # The ner-transformers module uses spellchecker library to check
    # misspellings in a given text
    ner-transformers:
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}
      tag: dbmdz-bert-large-cased-finetuned-conll03-english-0.0.2
      repo: semitechnologies/ner-transformers
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: ner-transformers
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
      envconfig:
        # enable for CUDA support. Your K8s cluster needs to be configured
        # accordingly and you need to explicitly set GPU requests & limits below
        enable_cuda: false

        # only used when cuda is enabled
        nvidia_visible_devices: all
        nvidia_driver_capabilities: compute,utility

        # only used when cuda is enabled
        ld_library_path: /usr/local/nvidia/lib64

      resources:
        requests:
          cpu: '1000m'
          memory: '3000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
        limits:
          cpu: '1000m'
          memory: '5000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
      
      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

    # The sum-transformers module makes result texts summarizations
    sum-transformers:
      enabled: false
      # You can set directly an inference URL of this module without deploying it with this release.
      # You can do so by setting a value for the `inferenceUrl` here AND by setting the `enable` to `false`
      inferenceUrl: {}
      tag: facebook-bart-large-cnn-1.0.0
      repo: semitechnologies/sum-transformers
      registry: docker.io
      replicas: 1
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      fullnameOverride: sum-transformers
      livenessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
        timeoutSeconds: 3
      readinessProbe:
        initialDelaySeconds: 120
        periodSeconds: 3
      envconfig:
        # enable for CUDA support. Your K8s cluster needs to be configured
        # accordingly and you need to explicitly set GPU requests & limits below
        enable_cuda: false

        # only used when cuda is enabled
        nvidia_visible_devices: all
        nvidia_driver_capabilities: compute,utility

        # only used when cuda is enabled
        ld_library_path: /usr/local/nvidia/lib64

      resources:
        requests:
          cpu: '1000m'
          memory: '3000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
        limits:
          cpu: '1000m'
          memory: '5000Mi'

          # enable if running with CUDA support
          # nvidia.com/gpu: 1
      
      # It is possible to add a ServiceAccount to this module's Pods, it can be
      # used in cases where the module is in a private registry and you want to
      # give access to the registry only to this pod.
      # NOTE: if not set the root `serviceAccountName` config will be used.
      serviceAccountName:

      # You can guide where the pods are scheduled on a per-module basis,
      # as well as for Weaviate overall. Each module accepts nodeSelector,
      # tolerations, and affinity configuration. If it is set on a per-
      # module basis, this configuration overrides the global config.

      nodeSelector:
      tolerations:
      affinity:

    # by choosing the default vectorizer module, you can tell Weaviate to always
    # use this module as the vectorizer if nothing else is specified. Can be
    # overwritten on a per-class basis.
    # set to text2vec-transformers if running with transformers instead
    default_vectorizer_module: none

  # It is also possible to configure authentication and authorization through a
  # custom configmap The authorization and authentication values defined in
  # values.yaml will be ignored when defining a custom config map.
  custom_config_map:
    enabled: false
    name: 'custom-config'

  # Pass any annotations to Weaviate pods
  annotations:

  nodeSelector:

  tolerations:

  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: "kubernetes.io/hostname"
            labelSelector:
              matchExpressions:
                - key: "app"
                  operator: In
                  values:
                    - weaviate
service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi


# Global node selector
# If set, this will apply to all dify components
# Individual components can be set to a different node selector
nodeSelector: {}

# Global tolerations
# If set, this will apply to all dify components
# Individual components can be set to a different tolerations
tolerations: []

# Global affinity
# If set, this will apply to all dify components
# Individual components can be set to a different affinity
affinity: {}

redis:
  enabled: true

###################################
# External postgres
# - these configs are only used when `externalPostgres.enabled` is true
###################################
externalPostgres:
  enabled: true
  username: "postgres"
  password: "difyai123456"
  address: localhost
  port: 5432
  dbName: dify
  maxOpenConns: 20
  maxIdleConns: 5

###################################
# External S3
# - these configs are only used when `externalS3.enabled` is true
###################################
externalS3:
  enabled: true
  endpoint: "https://xxx.r2.cloudflarestorage.com"
  accessKey: "ak-difyai"
  secretKey: "sk-difyai"
  useSSL: false
  bucketName: "difyai"
  rootPath: ""
  useIAM: false
  iamEndpoint: ""

###################################
# External Redis
# - these configs are only used when `externalRedis.enabled` is true
###################################
externalRedis:
  enabled: true
  host: "https://xxx.r2.cloudflarestorage.com"
  port: 6379
  username: "sk-difyai"
  password: ""
  useSSL: false

###################################
# External Weaviate
# - these configs are only used when `externalWeaviate.enabled` is true
###################################
externalWeaviate:
  enabled: true
  endpoint: "http://weaviate:8080"
  apiKey: "WVF5YThaHlkYwhGUSmCRgsX3tD5ngdN8pkih"


###################################
# External Qdrant
# - these configs are only used when `externalWeaviate.enabled` is false and `externalQdrant.enabled` is true
###################################
externalQdrant:
  enabled: true
  endpoint: "https://your-qdrant-cluster-url.qdrant.tech/"
  apiKey: "ak-difyai"
